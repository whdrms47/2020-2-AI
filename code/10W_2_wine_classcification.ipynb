{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "10W-2-wine-classcification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "CoosnIs0y1t9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c46f43e-2d38-4daa-bed7-1fed430a0439"
      },
      "source": [
        "#와인 데이터셋 불러오기\n",
        "import pandas as pd\n",
        "red =pd.read_csv('http://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv', sep=';')\n",
        "white =pd.read_csv('http://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv', sep=';')\n",
        "print(red.head())\n",
        "print(white.head())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   fixed acidity  volatile acidity  citric acid  ...  sulphates  alcohol  quality\n",
            "0            7.4              0.70         0.00  ...       0.56      9.4        5\n",
            "1            7.8              0.88         0.00  ...       0.68      9.8        5\n",
            "2            7.8              0.76         0.04  ...       0.65      9.8        5\n",
            "3           11.2              0.28         0.56  ...       0.58      9.8        6\n",
            "4            7.4              0.70         0.00  ...       0.56      9.4        5\n",
            "\n",
            "[5 rows x 12 columns]\n",
            "   fixed acidity  volatile acidity  citric acid  ...  sulphates  alcohol  quality\n",
            "0            7.0              0.27         0.36  ...       0.45      8.8        6\n",
            "1            6.3              0.30         0.34  ...       0.49      9.5        6\n",
            "2            8.1              0.28         0.40  ...       0.44     10.1        6\n",
            "3            7.2              0.23         0.32  ...       0.40      9.9        6\n",
            "4            7.2              0.23         0.32  ...       0.40      9.9        6\n",
            "\n",
            "[5 rows x 12 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "20BC97dazd9i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "432b5407-eb8b-4155-d8a7-3d53d79ba02d"
      },
      "source": [
        "#데이터셋 합치기\n",
        "red['type'] = 0\n",
        "white['type'] = 1\n",
        "print(red.head(2)) #레드와인\n",
        "print(white.head(2)) #화이트와인\n",
        "\n",
        "wine = pd.concat([red, white])#와인 데이터셋 합치기\n",
        "print(wine.describe())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   fixed acidity  volatile acidity  citric acid  ...  alcohol  quality  type\n",
            "0            7.4              0.70          0.0  ...      9.4        5     0\n",
            "1            7.8              0.88          0.0  ...      9.8        5     0\n",
            "\n",
            "[2 rows x 13 columns]\n",
            "   fixed acidity  volatile acidity  citric acid  ...  alcohol  quality  type\n",
            "0            7.0              0.27         0.36  ...      8.8        6     1\n",
            "1            6.3              0.30         0.34  ...      9.5        6     1\n",
            "\n",
            "[2 rows x 13 columns]\n",
            "       fixed acidity  volatile acidity  ...      quality         type\n",
            "count    6497.000000       6497.000000  ...  6497.000000  6497.000000\n",
            "mean        7.215307          0.339666  ...     5.818378     0.753886\n",
            "std         1.296434          0.164636  ...     0.873255     0.430779\n",
            "min         3.800000          0.080000  ...     3.000000     0.000000\n",
            "25%         6.400000          0.230000  ...     5.000000     1.000000\n",
            "50%         7.000000          0.290000  ...     6.000000     1.000000\n",
            "75%         7.700000          0.400000  ...     6.000000     1.000000\n",
            "max        15.900000          1.580000  ...     9.000000     1.000000\n",
            "\n",
            "[8 rows x 13 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EnzeIr7zzwga",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "outputId": "9a9533a2-8103-407f-90a1-604cc7441b65"
      },
      "source": [
        "#레드와인과 화이트와인 type 히스토그램\n",
        "import matplotlib.pyplot as plt\n",
        "plt.hist(wine['type'])\n",
        "plt.xticks([0, 1])\n",
        "plt.show()\n",
        "\n",
        "print(wine['type'].value_counts())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "1    4898\n",
            "0    1599\n",
            "Name: type, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "rTd1u1qJvbdf",
        "outputId": "775667df-be41-4f8c-ffd9-b3b155f5b926"
      },
      "source": [
        "#80% 훈련데이터(train_x), 20% 테스트 데이터(test_x) 만들기 \n",
        "import tensorflow as tf\n",
        "train_idx = int(len(wine_np) * 0.8)\n",
        "\n",
        "train_x, train_y = wine_np[:train_idx, :-1], wine_np[:train_idx, -1]\n",
        "test_x, test_y = wine_np[train_idx:, :-1], wine_np[train_idx:, -1]\n",
        "print(train_x[0])\n",
        "print(train_y[0])\n",
        "print(test_x[0])\n",
        "print(test_y[0])\n",
        "\n",
        "train_y = tf.keras.utils.to_categorical(train_y, num_classes=2)\n",
        "test_y = tf.keras.utils.to_categorical(test_y, num_classes=2)#원핫인코딩을 만들기위해 .to_categorical 지정\n",
        "print(train_y[0])\n",
        "print(test_y[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-70a3d6521879>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#80% 훈련데이터(train_x), 20% 테스트 데이터(test_x) 만들기\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwine_np\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m0.8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwine_np\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtrain_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwine_np\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtrain_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'wine_np' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5gO6IqI4xDPP",
        "outputId": "76d9efc8-7e59-49eb-ad72-0fd161e70a32"
      },
      "source": [
        "#품질 데이터 확인\n",
        "print(wine['quality'].describe())\n",
        "print(wine['quality'].value_counts())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "count    6497.000000\n",
            "mean        5.818378\n",
            "std         0.873255\n",
            "min         3.000000\n",
            "25%         5.000000\n",
            "50%         6.000000\n",
            "75%         6.000000\n",
            "max         9.000000\n",
            "Name: quality, dtype: float64\n",
            "6    2836\n",
            "5    2138\n",
            "7    1079\n",
            "4     216\n",
            "8     193\n",
            "3      30\n",
            "9       5\n",
            "Name: quality, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qy5OQ1Qpz1mN",
        "outputId": "06a4bb18-4e12-4382-a3cb-9ad34d92fbb3"
      },
      "source": [
        "# 품질을 3개의 범주 (좋음, 보통, 나쁨)으로 재분류\n",
        "# 기말고사에 나올 확률 있음\n",
        "wine.loc[wine['quality'] <= 5, 'new_quality'] = 0\n",
        "wine.loc[wine['quality'] == 6, 'new_quality'] = 1\n",
        "wine.loc[wine['quality'] >= 7, 'new_quality'] = 2\n",
        "\n",
        "print(wine['new_quality'].describe())\n",
        "print(wine['new_quality'].value_counts())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "count    6497.000000\n",
            "mean        0.829614\n",
            "std         0.731124\n",
            "min         0.000000\n",
            "25%         0.000000\n",
            "50%         1.000000\n",
            "75%         1.000000\n",
            "max         2.000000\n",
            "Name: new_quality, dtype: float64\n",
            "1.0    2836\n",
            "0.0    2384\n",
            "2.0    1277\n",
            "Name: new_quality, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 621
        },
        "id": "lG51v_q50R7r",
        "outputId": "bea3f788-877a-4f28-c578-1ef946312c9f"
      },
      "source": [
        "#내용들을 하나의 코드로 정리\n",
        "del wine['quality']\n",
        "wine_backup = wine.copy()\n",
        "wine_norm = (wine - wine.min()) / (wine.max() - wine.min())\n",
        "wine_norm['new_quality'] = wine_backup['new_quality']\n",
        "wine_shuffle = wine_norm.sample(frac=1)\n",
        "wine_np = wine_shuffle.to_numpy()\n",
        "\n",
        "train_idx = int(len(wine_np) * 0.8)\n",
        "train_X, train_Y = wine_up[:train_idx, :-1], wine_np[:train_idx, -1]\n",
        "test_X, test_Y = wine_np[train_idx:, :-1], wine_np[train_idx:, -1]\n",
        "train_Y = tf.keras.utils.to_categorical(train_y, num_classes=3)\n",
        "test_Y = tf.keras.utils.to_categorical(test_y, num_classes=3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2894\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2895\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'quality'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-655602bb755f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#내용들을 하나의 코드로 정리\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mdel\u001b[0m \u001b[0mwine\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'quality'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mwine_backup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mwine_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mwine\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mwine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mwine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mwine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mwine_norm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'new_quality'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwine_backup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'new_quality'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__delitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3709\u001b[0m             \u001b[0;31m# there was no match, this call should raise the appropriate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3710\u001b[0m             \u001b[0;31m# exception:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3711\u001b[0;31m             \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3712\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3713\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2895\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2897\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2898\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2899\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'quality'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "id": "g5YJoIvq2-BB",
        "outputId": "4a5e3961-2b56-43ee-da5e-a6c982a1f186"
      },
      "source": [
        "#와인 데이터셋 다함 분류 모델 생성 및 학습\n",
        "model = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(units=48, activation='relu', input_shape=(12,)),\n",
        "  tf.keras.layers.Dense(units=24, activation='relu'),\n",
        "  tf.keras.layers.Dense(units=12, activation='relu'),\n",
        "  tf.keras.layers.Dense(units=3, activation='softmax'),                             \n",
        "])\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.003), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(train_x, train_y, epochs=25, batch_size=32, validation_split=0.25)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-c8438f6ee448>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.003\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'train_x' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HMPW9fcP5oal"
      },
      "source": [
        "#필요 모듈 임포트\n",
        "#tensorflow와 tf.keras를 임포트\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "#문제와 정답 데이터 지정\n",
        "fashion_mnist = keras.datasets.fashion_mnist\n",
        "(train_images, train_Tabels), (test_images, test_labels) = fashion_mnist.load_data()\n",
        "#10개의 분류 이름 지정\n",
        "class_names = ['T-shirt/top', 'Truouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
        "\n",
        "#데이터 전처리\n",
        "#샘플 값을 정수(0~255)에서 부동소수(0~1)로 전환\n",
        "train_images, test_images = train_images / 255.0, test_images / 255.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4d_LqFL74rGh",
        "outputId": "ba00f2d3-3fe3-422d-96aa-a8cb4cbf2dd4"
      },
      "source": [
        "# Fashion MNIST 데이터셋 불러오기\n",
        "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
        "(train_X, train_Y), (test_X, test_Y) = fashion_mnist.load_data()\n",
        "\n",
        "print(len(train_X), len(test_X))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "60000 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "DWa6RvRX7j8Z",
        "outputId": "a60aa463-3f62-4ecf-b51e-a29cf3685156"
      },
      "source": [
        "#데이터 확인\n",
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(train_X[0], cmap='gray')\n",
        "plt.colorbar()\n",
        "plt.show()\n",
        "\n",
        "print(train_Y[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAATEAAAD4CAYAAACE9dGgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAaCUlEQVR4nO3dfYxV1bnH8e9TQN7LqyDiVHyBtPQNLfXaao3U2gvmpqhNqDZpudUW02iuJja51n9qYkyNrXpr4jUZXyImWi+JesWG1nKJiTXUFyAEEG6vSDGC4yBCkVd18Ll/nD3tgTN7rT1z3vYafp/kZM7s5+yz1+wZHtZe59lrmbsjIpKqT7W7ASIi9VASE5GkKYmJSNKUxEQkaUpiIpK0oa08mJnpo1CRJnN3q2f/+fPn++7duwu9du3atc+7+/x6jlevupKYmc0HfgMMAR5y9zsb0ioRaZvdu3ezZs2aQq81s8lNbk7UgC8nzWwIcD+wAJgNXG1msxvVMBFpH3cv9Igxsw4ze8HMNpvZ62Z2Y7b9NjPbaWbrs8dlVfv83My2mtlfzOyfY8eopyd2HrDV3bdlB34SWAhsruM9RaQEPvnkk0a9VQ9ws7uvM7OxwFozW5nF7nX3X1e/OOsIXQV8HjgV+B8zm+XuR/MOUM/A/nTg7arvd2TbjmFmS8xsjZkV65+KSFsV7YUV6Ym5e5e7r8ue7we20EeeqLIQeNLdP3T3vwJbqXSYcjX900l373T3ue4+t9nHEpHG6EcSm9zbSckeS/Le08xmAOcAr2SbbjCzDWb2iJlNyLYV6hxVqyeJ7QQ6qr4/LdsmIonrRxLb3dtJyR6dfb2fmY0BngJucvcPgAeAs4A5QBdw90DbWk8Sew2YaWZnmNlJVK5jl9fxfiJSEo26nAQws2FUEtjj7v509v7d7n7U3T8BHuQfl4z97hwNOIm5ew9wA/A8levcZe7++kDfT0TKo4GfThrwMLDF3e+p2j6t6mVXAJuy58uBq8xsuJmdAcwEXg0do646MXdfAayo5z1EpFzcvZGfTl4A/ADYaGbrs223UinJmgM4sB24Ljv262a2jEqVQw9wfeiTSWhxxb6IpKFR8wy6+0tAX3cQ5HZ+3P0O4I6ix1ASE5EaKU2WqiQmIjWUxEQkWf355LEMlMREpEYDB/abTklMRGqoJyYiydLlpIgkT0lMRJKmJCYiSVMSE5FkNfi2o6ZTEhORGuqJiUjSlMSkNCozoeSr94917NixwfiFF16YG/v9739f17FjP9uQIUNyYz09PXUdu16xtoe0IsEoiYlI0pTERCRZGtgXkeSpJyYiSVMSE5GkKYmJSLJ0A7iIJE9JTErjU58Kr8p39GhwIRnOPvvsYPzHP/5xMH748OHc2MGDB4P7HjlyJBh/9dXgSl511YLF6rhi5zW2fz1tC9W/xX6fRenTSRFJmnpiIpIsjYmJSPKUxEQkaUpiIpI0JTERSZbunRSR5KknJqURqimCeF3RN7/5zWD8W9/6VjC+Y8eO3Njw4cOD+44aNSoYv/TSS4Pxhx56KDfW3d0d3Df2j7jeeqwxY8bkxmK9oEOHDtV17CJOmCRmZtuB/cBRoMfd5zaiUSLSXidMEsvMc/fdDXgfESmJEy2JicggktrAfvgGsDgH/mhma81sSV8vMLMlZrbGzNbUeSwRaZHeqv3YowzqTWIXuvu5wALgejO76PgXuHunu8/VeJlIOhqVxMysw8xeMLPNZva6md2YbZ9oZivN7I3s64Rsu5nZfWa21cw2mNm5sWPUlcTcfWf2dRfwDHBePe8nIuXQwJ5YD3Czu88GzqfS2ZkN3AKscveZwKrse6h0iGZmjyXAA7EDDDiJmdloMxvb+xz4NrBpoO8nIuVQNIEVSWLu3uXu67Ln+4EtwHRgIbA0e9lS4PLs+ULgMa94GRhvZtNCx6hnYH8q8Ew2b9JQ4Al3/0Md7ydN8NFHH9W1/1e/+tVgfMaMGcF4qE4tNifX888/H4yfc845wfhdd92VG1uzJjxEu3HjxmB8y5Ytwfh554UvSkLndfXq1cF9//znP+fGDhw4ENy3qH6Md00+bry70907+3qhmc0AzgFeAaa6e1cWepdKPoFKgnu7arcd2bYucgw4ibn7NuDLA91fRMqrH59O7i4y3m1mY4CngJvc/YPqSSPd3c1swJ8S1DuwLyKDUCM/nTSzYVQS2OPu/nS2ubv3MjH7uivbvhPoqNr9tGxbLiUxETlGI8fErNLlehjY4u73VIWWA4uz54uBZ6u2/zD7lPJ8YF/VZWefVOwqIjUaWAN2AfADYKOZrc+23QrcCSwzs2uBt4BFWWwFcBmwFTgE/Ch2ACUxEanRqCTm7i8BeaumXNLH6x24vj/HUBITkRplqcYvQklsEAgtDxb7Y4xNZzN3bviDp/379wfjo0ePzo3NmjUruG8s/tprrwXjW7duzY2FpsIB+NrXvhaMX3nllcH4xx9/HIyH2h5bBu/DDz/MjcVKR4pI7d5JJTERqaGemIgkTUlMRJKmJCYiSVMSE5FkaWBfRJKnnpiIJC2lJGatbGw9d6oPZqE6r3rFfr8vv/xyMB6baicm9LP19PQE9613GqEjR47kxmKXS+vWrQvGQzVoEP/Z5s+fnxs788wzg/tOnz49GHf3uv6gZs2a5ffdd1+h1y5YsGBtu2dtVk9MRI5Rpvnzi1ASE5EaSmIikjR9OikiSVNPTESSpTExEUmekpiIJE1JTPqlnX8we/fuDcanTQsu+cfhw4eD8eHDh+fGhg4N//nF5vwK1YEBjBw5MjcWG7j+xje+EYx//etfD8Zjy9FNmTIlN/aHP7R/5UMlMRFJlu6dFJHkqScmIklTEhORpCmJiUjSlMREJFka2BeR5KknJskYNWpUMB6rd4rFDx06lBvbt29fcN/3338/GI/NdRb6hxibwy32c8XO29GjR4PxUE+no6MjuG8rpJTEwr8pwMweMbNdZrapattEM1tpZm9kXyc0t5ki0kq990/GHmUQTWLAo8Dx01DeAqxy95nAqux7ERkEiiawZJKYu78I7Dlu80JgafZ8KXB5g9slIm2UUhIb6JjYVHfvyp6/C0zNe6GZLQGWDPA4ItIGJ9Snk+7uoQVA3L0T6AQtFCKSgjL1soooMibWl24zmwaQfd3VuCaJSLuldDk50CS2HFicPV8MPNuY5ohIGaSUxKKXk2b2W+BiYLKZ7QB+AdwJLDOza4G3gEXNbORgV2/NUqgmKTYn16mnnhqMf/jhh3XFQ/OJxdaVDNWYAYwfPz4YD9WZxeq8TjrppGB8//79wfi4ceOC8Q0bNuTGYr+zuXPzl3ncvHlzcN+iypKgiogmMXe/Oid0SYPbIiIl0MjbjszsEeBfgF3u/oVs223AT4D3spfd6u4rstjPgWuBo8C/ufvzsWMM9HJSRAaxBl5OPkptnSnAve4+J3v0JrDZwFXA57N9/tPMhsQOoCQmIjUalcRy6kzzLASedPcP3f2vwFbgvNhOSmIiUqMfSWyyma2pehStCb3BzDZktzX23rY4HXi76jU7sm1BugFcRGr0Y2B/t7vnf9LQtweA2wHPvt4NXNPP9/g7JTEROUazyyfcvbv3uZk9CPwu+3YnUD2Fx2nZtiAlsRKI/cEMGRIe2wyVWHzve98L7nvKKacE4++9914wHloWDcK3r4wePTq4b2xKmliJRqi84+OPPw7uG1tOLvZzT5o0KRi///77c2Nz5swJ7htqW6xcp6hm3nZkZtOqblu8AuidIWc58ISZ3QOcCswEXo29n5KYiNRoVE8sp870YjObQ+VycjtwXXbM181sGbAZ6AGud/fwxGwoiYlIHxqVxHLqTB8OvP4O4I7+HENJTESOUaZbiopQEhORGkpiIpI0JTERSdoJNSmiiAwuGhOTfovVJMXqoUI2bdoUjMem0hk2bFgwXk8N25QpU4L7HjlyJBiPLekWavuIESOC+8Zq2Pbu3RuM79ixIxj//ve/nxv71a9+Fdz35ZdfDsYbQUlMRJKmJCYiSVMSE5FkNXJSxFZQEhORGuqJiUjSlMREJGlKYiKSNCWxJgnNlRSrV4otexabhyk0/1S9g6A9PT117R+yYsWKYPzgwYPB+OHDh4Px2NJmoX8MsbnKYr/TWK1XbM6wevaN/c5jbf/Sl76UG9u3b19w32ZTsauIJE+fTopI0tQTE5GkKYmJSLI0JiYiyVMSE5GkKYmJSNL06eQA1TM3VTNrrZrtoosuCsa/+93vBuMXXHBBbuzQoUPBfWNzcsXqwGJzoYV+Z7G2xf4eQutKQriOLNbTiLUtJnbeDhw4kBu78sorg/s+99xzA2pTUamNiYUrQAEze8TMdpnZpqptt5nZTjNbnz0ua24zRaSVehNZ7FEG0SQGPArM72P7ve4+J3uEy8JFJCkpJbHo5aS7v2hmM5rfFBEpi7IkqCKK9MTy3GBmG7LLzQl5LzKzJWa2xszW1HEsEWmR3kkRizzKYKBJ7AHgLGAO0AXcnfdCd+9097nuPneAxxKRFhtUl5N9cffu3udm9iDwu4a1SETariwJqogB9cTMbFrVt1cA4XXBRCQpg6onZma/BS4GJpvZDuAXwMVmNgdwYDtwXSMaE6opqtfEiROD8VNPPTUYnzlz5oD3jdX9zJo1KxiPrQ0ZmistVu80adKkYPydd94JxmNrQ4bqpWLrTsbW2xw1alQwvnr16tzYmDFjgvvGavdi40GxOcFC85Wdf/75wX1boSwJqogin05e3cfmh5vQFhEpgTL1soooVcW+iJRDWT55LEJJTERqpNQTq6dOTEQGqUYN7OfctjjRzFaa2RvZ1wnZdjOz+8xsa1aDem6RtiqJicgxiiawgr21R6m9bfEWYJW7zwRWZd8DLABmZo8lVOpRo5TERKRGo5KYu78I7Dlu80JgafZ8KXB51fbHvOJlYPxx5Vx9KtWYWOyj5dtvvz03dvLJJwf3HT9+fDAeK+8ITQvzt7/9LbhvbJqg/fv3B+OxUoPQcnOxJddCZQgAixYtCsbXrAnfTTZ27NjcWKx0ZMaMGcF4zBe/+MXcWKhdAG+//XYwHitdGTlyZDAeKvE4/fTTg/u2QpPHxKa6e1f2/F1gavZ8OlB94ndk27oIKFUSE5Fy6Menk5OPuy+60907i+7s7m5mdWVMJTEROUY/68R2D+C+6G4zm+buXdnl4q5s+06go+p1p2XbgjQmJiI1mnzb0XJgcfZ8MfBs1fYfZp9Sng/sq7rszKWemIjUaNSYWM5ti3cCy8zsWuAtoHfgdQVwGbAVOAT8qMgxlMREpEajkljObYsAl/TxWgeu7+8xlMRE5Bi9kyKmQklMRGqkdNtRy5NYqN7qvvvuC+47bVp+3VuszisWr2eJrtjyXLFjx2q5YsaNG5cbi9Uc3XnnncF4rG0//elPg/HQVD6xaXxWrVoVjG/bti0YD02fFJuCKFabN2zYsGA8ND0ShKfiee+994L7toKSmIgkTUlMRJKmJCYiydKkiCKSPH06KSJJU09MRJKmJCYiydKYWMCkSZP4zne+kxuP1TS9+eabubHYElyxeGxJt5BYzVCojgvic1fFlk0LLV3W3d2dGwNYunRpMH755ZcH488991wwHpoTLPY7+cpXvhKMz5s3LxgP1WrF6sCGDx8ejMdqA2NCtYOxv6eOjo7c2LvvvjvgNlVTEhORpGlgX0SSpctJEUmekpiIJE1JTESSpiQmIklTEhORZGlSxICenh527dqVG4/VS9WzhmHsvWM1S6G6oE9/+tPBfffsOX7t0GO99dZbwXisbaE5v2JzdsXWxHzmmWeC8Y0bNwbjoTqxWG1erJYrtt5naM6u2M8d+0ccq+WK7R9aKzRWgzZr1qzcWOycFJVSTyy62pGZdZjZC2a22cxeN7Mbs+0TzWylmb2RfZ3Q/OaKSCs0ebWjhiqyZFsPcLO7zwbOB643s9nALcAqd58JrMq+F5FBYFAlMXfvcvd12fP9wBYqS4svBHrvWVkKhO9PEZEkFE1gZUli/RoTM7MZwDnAK8DUqoUt3wWm5uyzBFgCMHLkyIG2U0RaqCwJqojCSczMxgBPATe5+wfVA5Pu7mbW50/t7p1AJ8D48ePTOTMiJ7CUPp0sMiaGmQ2jksAed/ens83dZjYti08D8j92FJGkDKrLSat0uR4Gtrj7PVWh5cBiKkuSLwaejb3XRx99xM6dO3PjsZOyY8eO3Njo0aOD+06ePDkYj300vXv37txYbImtoUPDpzk27Uvs4/wRI0bkxkJlKRBfWiz0cwN87nOfC8YPHjyYG4uVvezduzcYj523UNtD5RcQL8GI7R8bOjnllFNyY/v27QvuO2fOnNzYpk2bgvsWUaYEVUSRy8kLgB8AG81sfbbtVirJa5mZXQu8BSxqThNFpNUGVRJz95eAvMq8SxrbHBEpg0GVxETkxJPSwL6SmIgcYzCOiYnICUZJTESSpiQmIklTEstx+PBh1q9fnxt/+umnc2MA11xzTW4stqzZtm3bgvHYlDWh6XBidVyxmqHY1CtDhgwJxkPTEIWWBoP4H+uhQ4eC8a6urmA89P6xtsXq6+r5ndU7zU890wBBuA7tjDPOCO4bWoYvdtyilMREJFmNnhTRzLYD+4GjQI+7zzWzicB/ATOA7cAidw9XN+codNuRiJxYmnDb0Tx3n+Puc7PvGzaVl5KYiNRowb2TDZvKS0lMRGr0I4lNNrM1VY8lfb0d8EczW1sVLzSVVxEaExORY/Szl7W76hIxz4XuvtPMpgArzex/jzte7lReRagnJiI1Gnk56e47s6+7gGeA82jgVF5KYiJS45NPPin0iDGz0WY2tvc58G1gE/+YygsKTuWVe4xW1oPU02UEWLBgQW7sZz/7WXDfKVOmBOOxebNCdUGxeqdYnVesTixWLxV6/9DSYBCvB4rVwMXioZ8ttm+s7TGh/UO1VkXEfmexf+Ch+cQ2bNgQ3HfRovCsV+5e14kbNWqUn3322YVeu3HjxrWhy0kzO5NK7wsqw1dPuPsdZjYJWAZ8hmwqL3cPr22YQ2NiInKMRt4A7u7bgC/3sf19GjSVl5KYiNRQxb6IJE1JTESSpkkRRSRZmhRRRJKnJCYiSUspibW8Tiy0zmEzr8PnzZsXjP/yl78MxkN1ZuPGjQvuG1vbMVZHFqsTi9WphezaFS6Ujv19hNYRhfDv9MCBA8F9Y+clJtT22LxbsXnUYr/TlStXBuNbtmzJja1evTq4b0y9dWIjRozwjo6OQq/dunVrsE6sFdQTE5EaKfXElMRE5BiNnhSx2ZTERKSGemIikjQlMRFJmpKYiCRLxa4ikryUkli0TszMOoDHqMyB7UCnu//GzG4DfgK8l730VndfEXmvdM5MP3z2s58NxidPnhyMx9YwPO2004Lx7du358Zi9VBvvvlmMC7pqbdO7KSTTvKTTz650GvfeeedJOrEeoCb3X1dNkPjWjPrreS7191/3bzmiUg7pNQTiyaxbEWSruz5fjPbAkxvdsNEpD1SGxPr1xz7ZjYDOAd4Jdt0g5ltMLNHzGxCzj5LepdzqqulItIyLVh3smEKJzEzGwM8Bdzk7h8ADwBnAXOo9NTu7ms/d+9097ntvm4WkeJSSmKFPp00s2FUEtjj7v40gLt3V8UfBH7XlBaKSMuldNtRtCdmlSVjHga2uPs9VdunVb3sCirLMIlI4or2wsrSEytSYnEh8CdgI9Cbnm8FrqZyKenAduC6qmXJ896rHD+1yCBWb4nF0KFDPTa9VK89e/aUv8TC3V8C+jopwZowEUlXWXpZRahiX0RqKImJSNKUxEQkWZoUUUSSp56YiCRNSUxEkqYkJiLJKlMhaxFKYiJSQ0lMRJKmTydFJGnqiYlIslIbE+vXpIgicmJo5CwWZjbfzP5iZlvN7JZGt1VJTERqNCqJmdkQ4H5gATAbuNrMZjeyrbqcFJEaDRzYPw/Y6u7bAMzsSWAhsLlRB2h1EtsNvFX1/eRsWxmVtW1lbReobQPVyLad3oD3eJ5Km4oYcdz6GZ3u3ln1/XTg7arvdwD/VGf7jtHSJObuxyxmZ2Zr2j2hWp6ytq2s7QK1baDK1jZ3n9/uNvSHxsREpJl2Ah1V35+WbWsYJTERaabXgJlmdoaZnQRcBSxv5AHaPbDfGX9J25S1bWVtF6htA1XmttXF3XvM7AYq42xDgEfc/fVGHiO6UIiISJnpclJEkqYkJiJJa0sSa/ZtCPUws+1mttHM1h9X/9KOtjxiZrvMbFPVtolmttLM3si+TihR224zs53ZuVtvZpe1qW0dZvaCmW02s9fN7MZse1vPXaBdpThvqWr5mFh2G8L/AZdSKXx7Dbja3RtWwVsPM9sOzHX3thdGmtlFwAHgMXf/QrbtLmCPu9+Z/Qcwwd3/vSRtuw044O6/bnV7jmvbNGCau68zs7HAWuBy4F9p47kLtGsRJThvqWpHT+zvtyG4+0dA720Ichx3fxHYc9zmhcDS7PlSKv8IWi6nbaXg7l3uvi57vh/YQqVyvK3nLtAuqUM7klhftyGU6RfpwB/NbK2ZLWl3Y/ow1d27sufvAlPb2Zg+3GBmG7LLzbZc6lYzsxnAOcArlOjcHdcuKNl5S4kG9mtd6O7nUrnr/vrssqmUvDIWUKYamQeAs4A5QBdwdzsbY2ZjgKeAm9z9g+pYO89dH+0q1XlLTTuSWNNvQ6iHu+/Mvu4CnqFy+Vsm3dnYSu8Yy642t+fv3L3b3Y+6+yfAg7Tx3JnZMCqJ4nF3fzrb3PZz11e7ynTeUtSOJNb02xAGysxGZwOumNlo4NvApvBeLbccWJw9Xww828a2HKM3QWSuoE3nzswMeBjY4u73VIXaeu7y2lWW85aqtlTsZx8h/wf/uA3hjpY3og9mdiaV3hdUbsl6op1tM7PfAhdTmRalG/gF8N/AMuAzVKY1WuTuLR9gz2nbxVQuiRzYDlxXNQbVyrZdCPwJ2Aj0Tox1K5Xxp7adu0C7rqYE5y1Vuu1IRJKmgX0RSZqSmIgkTUlMRJKmJCYiSVMSE5GkKYmJSNKUxEQkaf8PVo2n+g0dlo4AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DqD7LnSc73Vy",
        "outputId": "94ffb060-6d4e-49aa-d14f-e9710c347e56"
      },
      "source": [
        "# 10개의 분류 이름 지정\n",
        "class_names = ['T-shirt/top', 'Truouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
        "print(class_names[train_Y[0]])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Ankle boot\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2DDQyc0H8JgR",
        "outputId": "d82ef551-28f3-471a-f6d3-eb28dd00c6d1"
      },
      "source": [
        "#데이터 정규환\n",
        "train_X = train_X / 255.0\n",
        "test_X = test_X /255.0\n",
        "\n",
        "print(train_X[0])\n",
        "#Fashion MNIST 분류 모델\n",
        "model = tf.keras.Sequential([\n",
        "  tf.keras.layers.Flatten(input_shape=(28,28)),\n",
        "  tf.keras.layers.Dense(units=128, activation='relu'),\n",
        "  tf.keras.layers.Dense(units=10, activation='softmax')                             \n",
        "])\n",
        "\n",
        "model.compile (optimizer = tf.keras.optimizers.Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "#Fashion MNIST 분류 모델 학습\n",
        "history = model.fit(train_X, train_Y, epochs=25, validation_split=0.25)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.00392157 0.         0.         0.05098039 0.28627451 0.\n",
            "  0.         0.00392157 0.01568627 0.         0.         0.\n",
            "  0.         0.00392157 0.00392157 0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.01176471 0.         0.14117647 0.53333333 0.49803922 0.24313725\n",
            "  0.21176471 0.         0.         0.         0.00392157 0.01176471\n",
            "  0.01568627 0.         0.         0.01176471]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.02352941 0.         0.4        0.8        0.69019608 0.5254902\n",
            "  0.56470588 0.48235294 0.09019608 0.         0.         0.\n",
            "  0.         0.04705882 0.03921569 0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.60784314 0.9254902  0.81176471 0.69803922\n",
            "  0.41960784 0.61176471 0.63137255 0.42745098 0.25098039 0.09019608\n",
            "  0.30196078 0.50980392 0.28235294 0.05882353]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.00392157\n",
            "  0.         0.27058824 0.81176471 0.8745098  0.85490196 0.84705882\n",
            "  0.84705882 0.63921569 0.49803922 0.4745098  0.47843137 0.57254902\n",
            "  0.55294118 0.34509804 0.6745098  0.25882353]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.00392157 0.00392157 0.00392157\n",
            "  0.         0.78431373 0.90980392 0.90980392 0.91372549 0.89803922\n",
            "  0.8745098  0.8745098  0.84313725 0.83529412 0.64313725 0.49803922\n",
            "  0.48235294 0.76862745 0.89803922 0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.71764706 0.88235294 0.84705882 0.8745098  0.89411765\n",
            "  0.92156863 0.89019608 0.87843137 0.87058824 0.87843137 0.86666667\n",
            "  0.8745098  0.96078431 0.67843137 0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.75686275 0.89411765 0.85490196 0.83529412 0.77647059\n",
            "  0.70588235 0.83137255 0.82352941 0.82745098 0.83529412 0.8745098\n",
            "  0.8627451  0.95294118 0.79215686 0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.00392157 0.01176471 0.\n",
            "  0.04705882 0.85882353 0.8627451  0.83137255 0.85490196 0.75294118\n",
            "  0.6627451  0.89019608 0.81568627 0.85490196 0.87843137 0.83137255\n",
            "  0.88627451 0.77254902 0.81960784 0.20392157]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.02352941 0.\n",
            "  0.38823529 0.95686275 0.87058824 0.8627451  0.85490196 0.79607843\n",
            "  0.77647059 0.86666667 0.84313725 0.83529412 0.87058824 0.8627451\n",
            "  0.96078431 0.46666667 0.65490196 0.21960784]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.01568627 0.         0.\n",
            "  0.21568627 0.9254902  0.89411765 0.90196078 0.89411765 0.94117647\n",
            "  0.90980392 0.83529412 0.85490196 0.8745098  0.91764706 0.85098039\n",
            "  0.85098039 0.81960784 0.36078431 0.        ]\n",
            " [0.         0.         0.00392157 0.01568627 0.02352941 0.02745098\n",
            "  0.00784314 0.         0.         0.         0.         0.\n",
            "  0.92941176 0.88627451 0.85098039 0.8745098  0.87058824 0.85882353\n",
            "  0.87058824 0.86666667 0.84705882 0.8745098  0.89803922 0.84313725\n",
            "  0.85490196 1.         0.30196078 0.        ]\n",
            " [0.         0.01176471 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.24313725 0.56862745 0.8\n",
            "  0.89411765 0.81176471 0.83529412 0.86666667 0.85490196 0.81568627\n",
            "  0.82745098 0.85490196 0.87843137 0.8745098  0.85882353 0.84313725\n",
            "  0.87843137 0.95686275 0.62352941 0.        ]\n",
            " [0.         0.         0.         0.         0.07058824 0.17254902\n",
            "  0.32156863 0.41960784 0.74117647 0.89411765 0.8627451  0.87058824\n",
            "  0.85098039 0.88627451 0.78431373 0.80392157 0.82745098 0.90196078\n",
            "  0.87843137 0.91764706 0.69019608 0.7372549  0.98039216 0.97254902\n",
            "  0.91372549 0.93333333 0.84313725 0.        ]\n",
            " [0.         0.22352941 0.73333333 0.81568627 0.87843137 0.86666667\n",
            "  0.87843137 0.81568627 0.8        0.83921569 0.81568627 0.81960784\n",
            "  0.78431373 0.62352941 0.96078431 0.75686275 0.80784314 0.8745098\n",
            "  1.         1.         0.86666667 0.91764706 0.86666667 0.82745098\n",
            "  0.8627451  0.90980392 0.96470588 0.        ]\n",
            " [0.01176471 0.79215686 0.89411765 0.87843137 0.86666667 0.82745098\n",
            "  0.82745098 0.83921569 0.80392157 0.80392157 0.80392157 0.8627451\n",
            "  0.94117647 0.31372549 0.58823529 1.         0.89803922 0.86666667\n",
            "  0.7372549  0.60392157 0.74901961 0.82352941 0.8        0.81960784\n",
            "  0.87058824 0.89411765 0.88235294 0.        ]\n",
            " [0.38431373 0.91372549 0.77647059 0.82352941 0.87058824 0.89803922\n",
            "  0.89803922 0.91764706 0.97647059 0.8627451  0.76078431 0.84313725\n",
            "  0.85098039 0.94509804 0.25490196 0.28627451 0.41568627 0.45882353\n",
            "  0.65882353 0.85882353 0.86666667 0.84313725 0.85098039 0.8745098\n",
            "  0.8745098  0.87843137 0.89803922 0.11372549]\n",
            " [0.29411765 0.8        0.83137255 0.8        0.75686275 0.80392157\n",
            "  0.82745098 0.88235294 0.84705882 0.7254902  0.77254902 0.80784314\n",
            "  0.77647059 0.83529412 0.94117647 0.76470588 0.89019608 0.96078431\n",
            "  0.9372549  0.8745098  0.85490196 0.83137255 0.81960784 0.87058824\n",
            "  0.8627451  0.86666667 0.90196078 0.2627451 ]\n",
            " [0.18823529 0.79607843 0.71764706 0.76078431 0.83529412 0.77254902\n",
            "  0.7254902  0.74509804 0.76078431 0.75294118 0.79215686 0.83921569\n",
            "  0.85882353 0.86666667 0.8627451  0.9254902  0.88235294 0.84705882\n",
            "  0.78039216 0.80784314 0.72941176 0.70980392 0.69411765 0.6745098\n",
            "  0.70980392 0.80392157 0.80784314 0.45098039]\n",
            " [0.         0.47843137 0.85882353 0.75686275 0.70196078 0.67058824\n",
            "  0.71764706 0.76862745 0.8        0.82352941 0.83529412 0.81176471\n",
            "  0.82745098 0.82352941 0.78431373 0.76862745 0.76078431 0.74901961\n",
            "  0.76470588 0.74901961 0.77647059 0.75294118 0.69019608 0.61176471\n",
            "  0.65490196 0.69411765 0.82352941 0.36078431]\n",
            " [0.         0.         0.29019608 0.74117647 0.83137255 0.74901961\n",
            "  0.68627451 0.6745098  0.68627451 0.70980392 0.7254902  0.7372549\n",
            "  0.74117647 0.7372549  0.75686275 0.77647059 0.8        0.81960784\n",
            "  0.82352941 0.82352941 0.82745098 0.7372549  0.7372549  0.76078431\n",
            "  0.75294118 0.84705882 0.66666667 0.        ]\n",
            " [0.00784314 0.         0.         0.         0.25882353 0.78431373\n",
            "  0.87058824 0.92941176 0.9372549  0.94901961 0.96470588 0.95294118\n",
            "  0.95686275 0.86666667 0.8627451  0.75686275 0.74901961 0.70196078\n",
            "  0.71372549 0.71372549 0.70980392 0.69019608 0.65098039 0.65882353\n",
            "  0.38823529 0.22745098 0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.15686275 0.23921569 0.17254902 0.28235294 0.16078431\n",
            "  0.1372549  0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]]\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten (Flatten)            (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 128)               100480    \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 101,770\n",
            "Trainable params: 101,770\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "1407/1407 [==============================] - 3s 2ms/step - loss: 0.5312 - accuracy: 0.8144 - val_loss: 0.4282 - val_accuracy: 0.8471\n",
            "Epoch 2/25\n",
            "1407/1407 [==============================] - 3s 2ms/step - loss: 0.3958 - accuracy: 0.8583 - val_loss: 0.3841 - val_accuracy: 0.8641\n",
            "Epoch 3/25\n",
            "1407/1407 [==============================] - 3s 2ms/step - loss: 0.3554 - accuracy: 0.8715 - val_loss: 0.3803 - val_accuracy: 0.8651\n",
            "Epoch 4/25\n",
            "1407/1407 [==============================] - 3s 2ms/step - loss: 0.3273 - accuracy: 0.8818 - val_loss: 0.3494 - val_accuracy: 0.8729\n",
            "Epoch 5/25\n",
            "1407/1407 [==============================] - 3s 2ms/step - loss: 0.3073 - accuracy: 0.8869 - val_loss: 0.3467 - val_accuracy: 0.8784\n",
            "Epoch 6/25\n",
            "1407/1407 [==============================] - 3s 2ms/step - loss: 0.2908 - accuracy: 0.8927 - val_loss: 0.3360 - val_accuracy: 0.8808\n",
            "Epoch 7/25\n",
            "1407/1407 [==============================] - 3s 2ms/step - loss: 0.2750 - accuracy: 0.8995 - val_loss: 0.3374 - val_accuracy: 0.8833\n",
            "Epoch 8/25\n",
            "1407/1407 [==============================] - 3s 2ms/step - loss: 0.2665 - accuracy: 0.9013 - val_loss: 0.3434 - val_accuracy: 0.8783\n",
            "Epoch 9/25\n",
            "1407/1407 [==============================] - 3s 2ms/step - loss: 0.2547 - accuracy: 0.9068 - val_loss: 0.3174 - val_accuracy: 0.8865\n",
            "Epoch 10/25\n",
            "1407/1407 [==============================] - 3s 2ms/step - loss: 0.2433 - accuracy: 0.9100 - val_loss: 0.3278 - val_accuracy: 0.8855\n",
            "Epoch 11/25\n",
            "1407/1407 [==============================] - 3s 2ms/step - loss: 0.2353 - accuracy: 0.9128 - val_loss: 0.3352 - val_accuracy: 0.8835\n",
            "Epoch 12/25\n",
            "1407/1407 [==============================] - 3s 2ms/step - loss: 0.2279 - accuracy: 0.9146 - val_loss: 0.3646 - val_accuracy: 0.8773\n",
            "Epoch 13/25\n",
            "1407/1407 [==============================] - 3s 2ms/step - loss: 0.2187 - accuracy: 0.9193 - val_loss: 0.3267 - val_accuracy: 0.8889\n",
            "Epoch 14/25\n",
            "1407/1407 [==============================] - 3s 2ms/step - loss: 0.2123 - accuracy: 0.9212 - val_loss: 0.3294 - val_accuracy: 0.8871\n",
            "Epoch 15/25\n",
            "1407/1407 [==============================] - 3s 2ms/step - loss: 0.2061 - accuracy: 0.9232 - val_loss: 0.3321 - val_accuracy: 0.8887\n",
            "Epoch 16/25\n",
            "1407/1407 [==============================] - 3s 2ms/step - loss: 0.2011 - accuracy: 0.9248 - val_loss: 0.3224 - val_accuracy: 0.8908\n",
            "Epoch 17/25\n",
            "1407/1407 [==============================] - 3s 2ms/step - loss: 0.1936 - accuracy: 0.9275 - val_loss: 0.3333 - val_accuracy: 0.8883\n",
            "Epoch 18/25\n",
            "1407/1407 [==============================] - 3s 2ms/step - loss: 0.1888 - accuracy: 0.9283 - val_loss: 0.3531 - val_accuracy: 0.8828\n",
            "Epoch 19/25\n",
            "1407/1407 [==============================] - 3s 2ms/step - loss: 0.1841 - accuracy: 0.9308 - val_loss: 0.3552 - val_accuracy: 0.8861\n",
            "Epoch 20/25\n",
            "1407/1407 [==============================] - 3s 2ms/step - loss: 0.1804 - accuracy: 0.9320 - val_loss: 0.3620 - val_accuracy: 0.8851\n",
            "Epoch 21/25\n",
            "1407/1407 [==============================] - 3s 2ms/step - loss: 0.1751 - accuracy: 0.9347 - val_loss: 0.3631 - val_accuracy: 0.8885\n",
            "Epoch 22/25\n",
            "1407/1407 [==============================] - 3s 2ms/step - loss: 0.1672 - accuracy: 0.9372 - val_loss: 0.3444 - val_accuracy: 0.8939\n",
            "Epoch 23/25\n",
            "1407/1407 [==============================] - 3s 2ms/step - loss: 0.1634 - accuracy: 0.9374 - val_loss: 0.3695 - val_accuracy: 0.8859\n",
            "Epoch 24/25\n",
            "1407/1407 [==============================] - 3s 2ms/step - loss: 0.1619 - accuracy: 0.9393 - val_loss: 0.3675 - val_accuracy: 0.8864\n",
            "Epoch 25/25\n",
            "1407/1407 [==============================] - 3s 2ms/step - loss: 0.1555 - accuracy: 0.9437 - val_loss: 0.3565 - val_accuracy: 0.8923\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UF1Kw0b-9g6J"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}